---
layout:     post
title:      autodiff实现
subtitle:   cse599w
date:       2018-12-26
author:     Dzw
header-img: img/autodiff/p4.png
catalog: 	 true
tags:
    - cse599w
    - autodiff
---

# Autodiff算法的思想

一般的思想是每次都计算一下梯度，不过这样会很繁琐，在考虑反向传播的时候还要考虑前向传播。

![](/img/autodiff/forward0.PNG)

一种改进如下，根据相邻结点来求梯度，即链式法则。

![](/img/autodiff/forward.png)

他的算法如下：

![](/img/autodiff/autodiff2.png)



```text
令最后结果out的grad=1,
获取nodes列表
```

![](/img/autodiff/p1.jpg)

```text
从后向前遍历nodes列表：
     梯度=相邻输出边的部分和相加
     输入的梯度=各自对应的输入节点梯度
     输入梯度的节点添加进node列表
```

![](/img/autodiff/p2.jpg)

![](/img/autodiff/p3.jpg)

![](/img/autodiff/autodiff3.PNG)

## 总结：

backprop和autodiff的对比还是很直观的。backprob只能按照前向传播原路返回,autodiff通过构造计算图可以一次遍历就能求出梯度，通过层层递进的方式进行梯度累加，更加直观，计算也更加方便。

![](/img/autodiff/p4.png)

参考论文[[1502.05767\] Automatic differentiation in machine learning: a survey](https://arxiv.org/abs/1502.05767)
